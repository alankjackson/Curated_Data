---
title: "Read in CoH Address POint data"
author: "Alan Jackson"
date: '2022-03-29'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

path <- "/home/ajackson/Dropbox/Rprojects/Curated_Data_Files/CoH_Address_Points/"

filename <- "COH_PDD_ADDRESS_POINTS_-_PDD.csv"

df <- read_csv(paste0(path, filename),
               col_types="nnccccccccccccccnnccccccccccccccc")

```

##    Quality control and Explore

Data read in mostly as character, except for lat long and xy coordinates.

Let's explore each column, with an eye towards possibly transforming them to 
a better data type (dates should be dates, for example)

```{r QC and Explore}
# Longitude

df %>% select(X) %>% 
  ggplot() +
  geom_histogram(aes(x=X))

# Latitude

df %>% select(Y) %>% 
  ggplot() +
  geom_histogram(aes(x=Y))

# Objectid

#   Can I safely convert to numeric?

df %>% select(OBJECTID) %>% 
  mutate(Objectid = as.integer(OBJECTID)) %>% 
  ggplot() +
  geom_histogram(aes(x=Objectid))

df %>% select(OBJECTID) %>% 
  mutate(Objectid = as.integer(OBJECTID)) %>% 
  count()
  
# ID (same question)

df %>% select(ID) %>% 
  mutate(Id = as.integer(ID)) %>% 
  ggplot() +
  geom_histogram(aes(x=Id))

# ADDR_ID (same question)

df %>% select(ADDR_ID) %>% 
  mutate(Addr_id = as.integer(ADDR_ID)) %>% 
  ggplot() +
  geom_histogram(aes(x=Addr_id))

# TYPES

df %>% select(TYPES) %>% 
  filter(!is.na(TYPES)) %>% 
  ggplot() +
  geom_histogram(aes(x=TYPES), stat="count") +
  coord_flip()

# STATUS

df %>% select(STATUS) %>% 
  ggplot() +
  geom_histogram(aes(x=STATUS), stat="count") +
  coord_flip()
```

Lat longs, and all the ID fields seem well enough behaved. Not sure about TYPES,
it seems to be left blank most of the time, so its usefulness is questionable.

Status is curious. It is always filled in, and some of the meaning seem obvious.
ABD is obviously abandoned. CNTY = county, COH = City of Houston. I think CP 
means that the location was reported? by Center Point? I don't know what the rest mean. Not really a clue. Except that UTA may have something to do with utilities.


```{r QC and Explore more}

# STREET_NUM

df %>% select(STREET_NUM) %>% 
  filter(str_starts(STREET_NUM, " ")) # test for beginning blank

df %>% select(STREET_NUM) %>% 
  filter(str_detect(STREET_NUM, " [0-9]")) # test for blank then number
  
dfnew <- df %>% 
  mutate(STREET_NUM = str_remove(STREET_NUM, "^[1-2]+/+[1-9]+")) %>% 
  mutate(STREET_NUM = str_remove(STREET_NUM, "[^0-9A-Z#/\\s]")) %>% 
  mutate(Street_alpha = str_trim(str_remove(STREET_NUM, "^\\d+")))  

dfnew %>% 
  filter(Street_alpha!="") %>% 
  ggplot() +
  geom_histogram(aes(x=Street_alpha), stat="count", na.rm=TRUE) +
  coord_flip() 
  
dfnew <- dfnew %>% 
  mutate(Street_num = as.numeric(str_extract(STREET_NUM,"^[0-9]+"))) %>% 
  filter(Street_num<49999)  

dfnew %>% 
  ggplot() +
  geom_histogram(aes(x=Street_num)) 
  

```
### STREET_NUM

Now it gets messy.

The street numbers have junk in them - sometimes.

4107 B
606 #3
1/2
35 1/2
13410.

So we'll try to clean up at least most of this. We'll create two new variables, Street_num and Street_alpha.

```{r QC and explore even more}

#   Fraction

dfnew %>% 
  filter(FRACTION!="") %>% 
  select(FRACTION) %>% 
  unique

```

Hmm... some trash in the FRACTION field. Period, square bracket, slash... 
Sometimes it matches what I have designated Street_alpha, but not always.

```{r PREFIX}

dfnew %>% 
  filter(PREFIX!="") %>% 
  select(PREFIX) %>% 
  unique

dfnew <- 
dfnew %>% 
  mutate(PREFIX=str_to_upper(PREFIX))

dfnew$PREFIX[!is.na(dfnew$PREFIX) & str_detect(dfnew$PREFIX, "[^NSEW]")] <- NA

```

A few bad entries. the "C" is pulled from the street number so can be deleted.
The lower case directions can be repaired.

```{r STREET NAME}

euclidean <- function(a, b) sqrt(sum((a - b)^2))

dfnew %>% count(STREET_NAME, sort=TRUE) %>% 
  filter(n<5)

dfnew %>% count(STREET_NAME, sort=TRUE) %>% 
  filter(n<10) %>% 
  ggplot() +
  geom_histogram(aes(x=n))

#   We have some bad names. Let's look at low occurrence names and have nearby 
#   names vote on the proper name

#   First shrink dataset size, then make an sf object
#   Nah, just use zipcode and text distance
#   But then look at physical distance as a fine tuning check

#   State Plane, Texas South Central Zone 5401, FIPS 4204, NAD83, EPSG 2278

dftest <- 
dfnew %>% 
#  head() %>% 
  #select(OBJECTID, STREET_NAME, Street_num, ZIPCODE)# %>% 
  select(OBJECTID, STREET_NAME, Street_num, ZIPCODE, X_COORD, Y_COORD)# %>% 
  #sf::st_as_sf(., coords=c("X_COORD", "Y_COORD"))

#   data frame of single occurrence names
df_singles <- dftest %>% 
  group_by(STREET_NAME) %>% 
  mutate(count=n()) %>% 
  filter(count<2) %>% 
  select(-count) %>% 
  filter(str_length(STREET_NAME)>3) %>% #  eliminate short names
  filter(!str_detect(STREET_NAME, "STREET")) %>% # eliminate A STREET, B STREET
  filter(!str_detect(STREET_NAME, "^\\d+TH")) %>% # eliminate 4TH, 5TH, etc
  filter(!str_detect(STREET_NAME, "^CR \\d+")) # eliminate county roads

#   data frame of double occurrence names
df_doubles <- dftest %>% 
  group_by(STREET_NAME) %>% 
  mutate(count=n()) %>% 
  filter(count==2) %>% 
  select(-count) %>% 
  filter(str_length(STREET_NAME)>3) %>% #  eliminate short names
  filter(!str_detect(STREET_NAME, "STREET")) %>% # eliminate A STREET, B STREET
  filter(!str_detect(STREET_NAME, "^\\d+TH")) %>% # eliminate 4TH, 5TH, etc
  filter(!str_detect(STREET_NAME, "^CR \\d+")) # eliminate county roads

##    function to get text distances and geometric distances

get_corrections <- function(df_test, df_base, text_dist, geom_dist, min_votes){
  tmp <- NULL
  for (i in 1:nrow(df_test)) {
    foo <- df_test[i,]
    foobar <- 
    df_base %>% filter(ZIPCODE==foo$ZIPCODE) %>% 
      mutate(adist=adist(STREET_NAME, foo$STREET_NAME),
             bad_X=foo$X_COORD,
             bad_Y=foo$Y_COORD,
             bad_num=foo$Street_num,
             bad_name=foo$STREET_NAME,
             bad_id=foo$OBJECTID) %>% 
      filter(adist == text_dist) %>% 
      mutate(eucdist=sqrt((X_COORD - bad_X)^2 +
                          (Y_COORD-bad_Y)^2)) %>% 
      group_by(STREET_NAME) %>%
         summarize(n=n(),
                   Street_num=last(bad_num),
                   STREET_NAME=last(STREET_NAME),
                   bad_name=last(bad_name),
                   bad_id=last(bad_id),
                   min_dist=min(eucdist)
                   ) %>%
      ungroup() %>%
      filter(n>min_votes,
             min_dist<geom_dist)
    
      tmp <- bind_rows(tmp, foobar) 
  }
  return(tmp)
}

#  Loop through singles, get distances to all in zipcode, then get text distance

tmp <- get_corrections(df_singles, dftest, 1, 1060, 3)

df_singles <- df_singles[!df_singles$OBJECTID %in% tmp$bad_id,]

tmp2 <- get_corrections(df_singles, dftest, 2, 300, 5)

df_singles <- df_singles[!df_singles$OBJECTID %in% tmp2$bad_id,]
df_singles <- df_singles %>% filter(!OBJECTID=="76158") %>% 
                             filter(!OBJECTID=="705381")

tmp3 <- get_corrections(df_singles, dftest, 3, 300, 9)
    
#------   Now do doubles

tmp4 <- get_corrections(df_doubles, dftest, 1, 500, 8)


```





