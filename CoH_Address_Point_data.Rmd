---
title: "Read in CoH Address POint data"
author: "Alan Jackson"
date: '2022-03-29'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

path <- "/home/ajackson/Dropbox/Rprojects/Curated_Data_Files/CoH_Address_Points/"

filename <- "COH_PDD_ADDRESS_POINTS_-_PDD.csv"

df <- read_csv(paste0(path, filename),
               col_types="nnccccccccccccccnnccccccccccccccc")

```

##    Quality control and Explore

Data read in mostly as character, except for lat long and xy coordinates.

Let's explore each column, with an eye towards possibly transforming them to 
a better data type (dates should be dates, for example)

```{r QC and Explore}
# Longitude

df %>% select(X) %>% 
  ggplot() +
  geom_histogram(aes(x=X))

# Latitude

df %>% select(Y) %>% 
  ggplot() +
  geom_histogram(aes(x=Y))

# Objectid

#   Can I safely convert to numeric?

df %>% select(OBJECTID) %>% 
  mutate(Objectid = as.integer(OBJECTID)) %>% 
  ggplot() +
  geom_histogram(aes(x=Objectid))

df %>% select(OBJECTID) %>% 
  mutate(Objectid = as.integer(OBJECTID)) %>% 
  count()
  
# ID (same question)

df %>% select(ID) %>% 
  mutate(Id = as.integer(ID)) %>% 
  ggplot() +
  geom_histogram(aes(x=Id))

# ADDR_ID (same question)

df %>% select(ADDR_ID) %>% 
  mutate(Addr_id = as.integer(ADDR_ID)) %>% 
  ggplot() +
  geom_histogram(aes(x=Addr_id))

# TYPES

df %>% select(TYPES) %>% 
  filter(!is.na(TYPES)) %>% 
  ggplot() +
  geom_histogram(aes(x=TYPES), stat="count") +
  coord_flip()

# STATUS

df %>% select(STATUS) %>% 
  ggplot() +
  geom_histogram(aes(x=STATUS), stat="count") +
  coord_flip()
```

Lat longs, and all the ID fields seem well enough behaved. Not sure about TYPES,
it seems to be left blank most of the time, so its usefulness is questionable.

Status is curious. It is always filled in, and some of the meaning seem obvious.
ABD is obviously abandoned. CNTY = county, COH = City of Houston. I think CP 
means that the location was reported? by Center Point? I don't know what the rest mean. Not really a clue. Except that UTA may have something to do with utilities.


```{r QC and Explore more}

# STREET_NUM

df %>% select(STREET_NUM) %>% 
  filter(str_starts(STREET_NUM, " ")) # test for beginning blank

df %>% select(STREET_NUM) %>% 
  filter(str_detect(STREET_NUM, " [0-9]")) # test for blank then number
  
dfnew <- df %>% 
  mutate(STREET_NUM = str_remove(STREET_NUM, "^[1-2]+/+[1-9]+")) %>% 
  mutate(STREET_NUM = str_remove(STREET_NUM, "[^0-9A-Z#/\\s]")) %>% 
  mutate(Street_alpha = str_trim(str_remove(STREET_NUM, "^\\d+")))  

dfnew %>% 
  filter(Street_alpha!="") %>% 
  ggplot() +
  geom_histogram(aes(x=Street_alpha), stat="count", na.rm=TRUE) +
  coord_flip() 
  
dfnew <- dfnew %>% 
  mutate(Street_num = as.numeric(str_extract(STREET_NUM,"^[0-9]+"))) %>% 
  filter(Street_num<49999)  

dfnew %>% 
  ggplot() +
  geom_histogram(aes(x=Street_num)) 
  

```
### STREET_NUM

Now it gets messy.

The street numbers have junk in them - sometimes.

4107 B
606 #3
1/2
35 1/2
13410.

So we'll try to clean up at least most of this. We'll create two new variables, Street_num and Street_alpha.

```{r QC and explore even more}

#   Fraction

dfnew %>% 
  filter(FRACTION!="") %>% 
  select(FRACTION) %>% 
  unique

```

Hmm... some trash in the FRACTION field. Period, square bracket, slash... 
Sometimes it matches what I have designated Street_alpha, but not always.

```{r PREFIX}

dfnew %>% 
  filter(PREFIX!="") %>% 
  select(PREFIX) %>% 
  unique

dfnew <- 
dfnew %>% 
  mutate(PREFIX=str_to_upper(PREFIX))

dfnew$PREFIX[!is.na(dfnew$PREFIX) & str_detect(dfnew$PREFIX, "[^NSEW]")] <- NA

```

A few bad entries. the "C" is pulled from the street number so can be deleted.
The lower case directions can be repaired.

```{r STREET NAME}

euclidean <- function(a, b) sqrt(sum((a - b)^2))

dfnew %>% count(STREET_NAME, sort=TRUE) %>% 
  filter(n<5)

dfnew %>% count(STREET_NAME, sort=TRUE) %>% 
  filter(n<10) %>% 
  ggplot() +
  geom_histogram(aes(x=n))

#   We have some bad names. Let's look at low occurrence names and have nearby 
#   names vote on the proper name

#   First shrink dataset size, then make an sf object
#   Nah, just use zipcode and text distance
#   But then look at physical distance as a fine tuning check

#   State Plane, Texas South Central Zone 5401, FIPS 4204, NAD83, EPSG 2278

dftest <- 
dfnew %>% 
#  head() %>% 
  #select(OBJECTID, STREET_NAME, Street_num, ZIPCODE)# %>% 
  select(OBJECTID, STREET_NAME, Street_num, ZIPCODE, X_COORD, Y_COORD)# %>% 
  #sf::st_as_sf(., coords=c("X_COORD", "Y_COORD"))

#   data frame of single occurrence names
df_singles <- dftest %>% 
  group_by(STREET_NAME) %>% 
  mutate(count=n()) %>% 
  filter(count<2) %>% 
  select(-count) %>% 
  filter(str_length(STREET_NAME)>3) %>% #  eliminate short names
  filter(!str_detect(STREET_NAME, "STREET")) %>% # eliminate A STREET, B STREET
  filter(!str_detect(STREET_NAME, "^\\d+TH")) %>% # eliminate 4TH, 5TH, etc
  filter(!str_detect(STREET_NAME, "^CR \\d+")) # eliminate county roads

#   data frame of double occurrence names
df_doubles <- dftest %>% 
  group_by(STREET_NAME) %>% 
  mutate(count=n()) %>% 
  filter(count==2) %>% 
  select(-count) %>% 
  filter(str_length(STREET_NAME)>3) %>% #  eliminate short names
  filter(!str_detect(STREET_NAME, "STREET")) %>% # eliminate A STREET, B STREET
  filter(!str_detect(STREET_NAME, "^\\d+TH")) %>% # eliminate 4TH, 5TH, etc
  filter(!str_detect(STREET_NAME, "^CR \\d+")) # eliminate county roads

##    function to get text distances and geometric distances

get_corrections <- function(df_test, df_base, text_dist, geom_dist, min_votes){
  tmp <- NULL
  for (i in 1:nrow(df_test)) {
    foo <- df_test[i,]
    foobar <- 
    df_base %>% filter(ZIPCODE==foo$ZIPCODE) %>% 
      mutate(adist=adist(STREET_NAME, foo$STREET_NAME),
             bad_X=foo$X_COORD,
             bad_Y=foo$Y_COORD,
             bad_num=foo$Street_num,
             bad_name=foo$STREET_NAME,
             bad_id=foo$OBJECTID) %>% 
      filter(adist == text_dist) %>% 
      mutate(eucdist=sqrt((X_COORD - bad_X)^2 +
                          (Y_COORD-bad_Y)^2)) %>% 
      group_by(STREET_NAME) %>%
         summarize(n=n(),
                   Street_num=last(bad_num),
                   STREET_NAME=last(STREET_NAME),
                   bad_name=last(bad_name),
                   bad_id=last(bad_id),
                   min_dist=min(eucdist)
                   ) %>%
      ungroup() %>%
      filter(n>min_votes,
             min_dist<geom_dist)
    
      tmp <- bind_rows(tmp, foobar) 
  }
  return(tmp)
}

#  Loop through singles, get distances to all in zipcode, then get text distance

tmp <- get_corrections(df_singles, dftest, 1, 1060, 3)

df_singles <- df_singles[!df_singles$OBJECTID %in% tmp$bad_id,]
tmp[duplicated(tmp$bad_id),]
tmp <- tmp %>% filter(!STREET_NAME=="INTERCONTINENT",
                      !STREET_NAME=="MARY")

tmp2 <- get_corrections(df_singles, dftest, 2, 300, 5)

df_singles <- df_singles[!df_singles$OBJECTID %in% tmp2$bad_id,]
df_singles <- df_singles %>% filter(!OBJECTID=="76158") %>% 
                             filter(!OBJECTID=="705381")
tmp2[duplicated(tmp2$bad_id),]

tmp3 <- get_corrections(df_singles, dftest, 3, 300, 9)
tmp3[duplicated(tmp3$bad_id),]
    
#------   Now do doubles

tmp4 <- get_corrections(df_doubles, dftest, 1, 500, 8)
tmp4[duplicated(tmp4$bad_id),]

#------ Now update the original by adding a new field

dfnew <- dfnew %>% mutate(New_street=STREET_NAME)

dfnew[dfnew$OBJECTID %in% tmp$bad_id,]$New_street <- tmp$STREET_NAME 
dfnew[dfnew$OBJECTID %in% tmp2$bad_id,]$New_street <- tmp2$STREET_NAME 
dfnew[dfnew$OBJECTID %in% tmp3$bad_id,]$New_street <- tmp3$STREET_NAME 
dfnew[dfnew$OBJECTID %in% tmp4$bad_id,]$New_street <- tmp4$STREET_NAME 

saveRDS(dfnew, paste0(path, "temporary_intermediate_file"))

```


```{r suffixes}

dfnew %>% 
  filter(SUFFIX!="") %>% 
  select(SUFFIX) %>% 
  unique

dfnew$SUFFIX[!is.na(dfnew$SUFFIX) & str_detect(dfnew$SUFFIX, "[^NSEW]")] <- NA

```

```{r street type}

dfnew %>% 
  filter(STREET_TYPE!="") %>% 
  select(STREET_TYPE) %>% 
  unique

Street_types <- 
dfnew %>% 
      group_by(STREET_TYPE) %>%
         summarize(n=n(),
                   STREET_TYPE=last(STREET_TYPE)) %>% 
  arrange(-n)

#   a lot of mess here. Will use a similar strategy as used for street names.
#   look at nearby friends and try to grab the type from them. Use total dataset
#   n value to establish the "standard".
#   Two tasks - look for missing types by checking nearby friends
#   And check the existing type against the standards

Allowed_types <- c(
  "ALY", "ANX", "ARC", "AVE", "BYU", "BCH", "BND", "BLF", "BLFS", "BTM", "BLVD",
  "BR", "BRG", "BRK", "BRKS", "BG", "BGS", "BYP", "CP", "CYN", "CPE", "CSWY", "CTR",
  "CTRS", "CIR", "CIRS", "CLF", "CLFS", "CLB", "CMN", "CMNS", "COR", "CORS",
  "CRSE", "CT", "CTS", "CV", "CVS", "CRK", "CRES", "CRST", "XING", "XRD", "XRDS",
  "CURV", "DL", "DM", "DV", "DR", "DRS", "EST", "ESTS", "EXPY", "EXT", "EXTS", "FALL",
  "FLS", "FRY", "FLD", "FLDS", "FLT", "FLTS", "FRD", "FRDS", "FRST", "FRG", "FRGS",
  "FRK", "FRKS", "FT", "FWY", "GDN", "GDNS", "GTWY", "GLN", "GLNS", "GRN", "GRNS",
  "GRV", "GRVS", "HBR", "HBRS", "HVN", "HTS", "HWY", "HL", "HLS", "HOLW", "INLT",
  "IS", "ISS", "ISLE", "JCT", "JCTS", "KY", "KYS", "KNL", "KNLS", "LK", "LKS",
  "LAND", "LNDG", "LN", "LGT", "LGTS", "LF", "LCK", "LCKS", "LDG", "LOOP", "MALL",
  "MNR", "MNRS", "MDW", "MDWS", "MEWS", "ML", "MLS", "MSN", "MTWY", "MT", "MTN",
  "MTNS", "NCK", "ORCH", "OVAL", "OPAS", "PARK", "PKWY", "PASS", "PSGE", "PATH",
  "PIKE", "PNE", "PNES", "PL", "PLN", "PLNS", "PLZ", "PT", "PTS", "PRT", "PRTS",
  "PR", "RADL", "RAMP", "RNCH", "RPD", "RPDS", "RST", "RDG", "RDGS", "RIV", "RD",
  "RDS", "RTE", "ROW", "RUE", "RUN", "SHL", "SHLS", "SHR", "SHRS", "SKWY", "SPG",
  "SPGS", "SPUR", "SQ", "SQS", "STA", "STRA", "STRM", "ST", "STS", "SMT", "TER",
  "TRWY", "TRCE", "TRAK", "TRFY", "TRL", "TRLR", "TUNL", "TPKE", "UPAS", "UN",
  "UNS", "VLY", "VLYS", "VIA", "VW", "VWS", "VLG", "VLGS", "VL", "VIS", "WALK",
  "WALL", "WAY", "WAYS", "WL", "WLS")


#   Let's look for erroneous types

Street_types %>% filter(!is.na(STREET_TYPE)) %>% 
  filter(!STREET_TYPE %in% Allowed_types)

#   Well that is simple enough. In Houston, apparently, "Speedway" is a street
#   type, so I'll leave that one alone. The rest I can update to the correct
#   value.

dfnew <- dfnew %>% 
  mutate(STREET_TYPE=str_replace(STREET_TYPE, "^PKY$", "PKWY")) %>% 
  mutate(STREET_TYPE=str_replace(STREET_TYPE, "^ROAD$", "RD")) %>% 
  mutate(STREET_TYPE=str_replace(STREET_TYPE, "^LANE$", "LN")) %>% 
  mutate(STREET_TYPE=str_replace(STREET_TYPE, "^TWY$", "CT"))  # not a tollway
  
#   Look at the NA's to see if they make sense

#   For each street/zip pair sum up # types

tmp <- 
dfnew %>% group_by(ZIPCODE, STREET_NAME) %>% 
      summarise(n=n(),
                sumNA = sum(is.na(STREET_TYPE)),
                NotNAs=list(unique(STREET_TYPE[!is.na(STREET_TYPE)]))) %>% 
  filter(!sumNA==n) %>% 
  mutate(NotNA=n-sumNA) %>% 
  mutate(Flag=lengths(NotNAs)) %>% 
  filter(sumNA>0) %>% 
  mutate(NotNAs=paste(NotNAs)) %>% # convert list to string 
  filter(Flag==1)  # remove ambiguous cases where there are multiple types

#   Let's first fix things that are not NA that should be
#   

tmp_rm_not_na <- tmp %>% 
  filter(n>9) %>% # need at least 10 to believe statistics
  mutate(foo=(NotNA/n)) %>% 
  filter((NotNA/n)<0.151) %>% 
  filter(!NotNAs=="CT") # don't trust 'court', leave alone

#   Apply what is left to NA that field

for (i in 1:nrow(tmp_rm_not_na)){
  dfnew$STREET_TYPE[(dfnew$ZIPCODE==tmp_rm_not_na[[i,1]]) & 
          (dfnew$STREET_NAME==tmp_rm_not_na[[i,2]])] <- NA
}
  
# Now let's fix things that are NA but shouldn't be

tmp_rm_na <- tmp %>% 
  filter(n>9) %>% # need at least 10 to believe statistics
  mutate(foo=(NotNA/n)) %>% 
  filter((NotNA/n)>0.810) %>% 
  filter(!NotNAs=="CT") %>% # don't trust 'court', leave alone
  filter(!NotNAs=="CIR") %>% # don't trust 'circle', leave alone
  filter(!NotNAs=="PL") # don't trust 'place', leave alone

#   Apply what is left to fill that field

eraseme <- dfnew
for (i in 1:nrow(tmp_rm_na)){
  dfnew$STREET_TYPE[(dfnew$ZIPCODE==tmp_rm_na[[i,1]]) & 
          (dfnew$STREET_NAME==tmp_rm_na[[i,2]])] <- tmp_rm_na[[i,5]]
}
  


```







